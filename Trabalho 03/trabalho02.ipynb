{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 03 - Classificação com Árvore de Decisão "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando a base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro irei carregar a base de dados do csv e depois vou transformar as classes \"good\" e \"vgood\" na classe \"acc\" para que o problema se torne binário. Basicamente vou subistituir cada instância de vgoog e good por acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buying_Price</th>\n",
       "      <th>Maintenance_Price</th>\n",
       "      <th>No_of_Doors</th>\n",
       "      <th>Person_Capacity</th>\n",
       "      <th>Size_of_Luggage</th>\n",
       "      <th>Safety</th>\n",
       "      <th>Car_Acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Buying_Price Maintenance_Price No_of_Doors Person_Capacity  \\\n",
       "1718          low               low       5more               4   \n",
       "1719          low               low       5more            more   \n",
       "1720          low               low       5more            more   \n",
       "1721          low               low       5more            more   \n",
       "1722          low               low       5more            more   \n",
       "1723          low               low       5more            more   \n",
       "1724          low               low       5more            more   \n",
       "1725          low               low       5more            more   \n",
       "1726          low               low       5more            more   \n",
       "1727          low               low       5more            more   \n",
       "\n",
       "     Size_of_Luggage Safety Car_Acceptability  \n",
       "1718             big   high               acc  \n",
       "1719           small    low             unacc  \n",
       "1720           small    med               acc  \n",
       "1721           small   high               acc  \n",
       "1722             med    low             unacc  \n",
       "1723             med    med               acc  \n",
       "1724             med   high               acc  \n",
       "1725             big    low             unacc  \n",
       "1726             big    med               acc  \n",
       "1727             big   high               acc  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df = pd.read_csv(\"car.csv\")\n",
    "\n",
    "car_df[\"Car_Acceptability\"] = car_df[\"Car_Acceptability\"].replace(\n",
    "    {\"good\": \"acc\", \"vgood\": \"acc\"}\n",
    ")\n",
    "\n",
    "car_df.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando uma função para medir entropia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEntropy(labels):\n",
    "    \"\"\"Calcula a entropia de uma série de rótulos\"\"\"\n",
    "\n",
    "    valores, contagens = np.unique(labels, return_counts=True)\n",
    "    probabilidades = contagens / len(labels)\n",
    "\n",
    "    return -np.sum([p * np.log2(p) for p in probabilidades if p > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a árvore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decisionTreeNode:\n",
    "\n",
    "    def __init__(self, depth: int = 0, max_depth: int = 4):\n",
    "        \n",
    "        self.attribute = None\n",
    "        self.nodes = {}\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.predicted_class = None\n",
    "        self.information_gain = 0 \n",
    "\n",
    "    \n",
    "    def fit(self, X, y, available_atributes):\n",
    "\n",
    "        if len(set(y)) == 1:\n",
    "            self.predicted_class = y.iloc[0]\n",
    "            return\n",
    "        \n",
    "        # Condições de parada: Todos os atributos utilizados ou profundidade máxima atingida\n",
    "        if len(available_atributes) == 0 or self.depth >= self.max_depth:\n",
    "            self.predicted_class = y.mode()[0]\n",
    "            return\n",
    "        \n",
    "        base_entropy = calcEntropy(y)\n",
    "\n",
    "        best_attribute = None\n",
    "        best_gain = -1\n",
    "\n",
    "        # Calculando o ganho de informação de cada atributo\n",
    "        for attribute in available_atributes:\n",
    "            gain = self._information_gain(X,y, attribute, base_entropy)\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_attribute = attribute\n",
    "        \n",
    "        # Condição de parada: Sem ganho de informação\n",
    "        # Também salvo o ganho de informação no nó\n",
    "        if best_gain <= 0:\n",
    "            self.predicted_class = y.mode()[0]\n",
    "            self.information_gain = best_gain \n",
    "            return\n",
    "        \n",
    "        self.attribute = best_attribute\n",
    "        self.information_gain = best_gain\n",
    "        \n",
    "        remaning_attributes = [a for a in available_atributes if a !=best_attribute]\n",
    "\n",
    "        # Criando nós filhos \n",
    "        for value in X[best_attribute].unique():\n",
    "            subset_X = X[X[best_attribute] == value]\n",
    "            subset_y = y[X[best_attribute] == value]\n",
    "\n",
    "            child_node = decisionTreeNode(depth= self.depth+1, max_depth= self.max_depth)\n",
    "            child_node.fit(subset_X, subset_y, remaning_attributes)\n",
    "\n",
    "            self.nodes[value] = child_node\n",
    "        \n",
    "    \n",
    "    def _information_gain(self, X, y, attribute, base_entropy) -> float:\n",
    "\n",
    "        # Pego todos os possíveis valores para um dado tipo de atributo\n",
    "        values = X[attribute].unique()\n",
    "        weighted_entropy = 0\n",
    "\n",
    "\n",
    "        for value in values:\n",
    "            \"\"\"\n",
    "            1. Em cada valor obtido acima, filtro amostras em y que tenham o \n",
    "            mesmo valor no atributo.\n",
    "            2. Pondero o peso dividindo a quantidade de amostas com aquele valor\n",
    "            pela quantidade total de amostras.\n",
    "            3. Calulo a entropia daquele subconjunto e depois calculo a entropia \n",
    "            ponderada.\n",
    "            4. O ganho de entropia é a entropia atual menos a entropia ponderada.\n",
    "            \"\"\"\n",
    "            subset_y = y[X[attribute] == value]\n",
    "            weight = len(subset_y) / len(y)\n",
    "\n",
    "            entropy_subset = calcEntropy(subset_y)\n",
    "            weighted_entropy += weight * entropy_subset\n",
    "        \n",
    "        information_gain = base_entropy - weighted_entropy\n",
    "\n",
    "        return information_gain\n",
    "\n",
    "    def predict(self, sample):\n",
    "        \"\"\"\n",
    "        Essa função percorre a árvore até encontrar uma folha com a classe prevista\n",
    "        \"\"\"\n",
    "\n",
    "        # Retorna a classe prevista\n",
    "        if self.predicted_class is not None:\n",
    "            return self.predicted_class\n",
    "        \n",
    "        attr_value = sample[self.attribute]\n",
    "        \n",
    "        # Se o valor estiver entre os nós filhos, continua descendo\n",
    "        if attr_value in self.nodes:\n",
    "            return self.nodes[attr_value].predict(sample)\n",
    "        \n",
    "        # Se o valor for desconhecido, retorna a classe mais comum\n",
    "        return self.predicted_class\n",
    "\n",
    "    def total_information_gain(self):\n",
    "        if not self.nodes:  # Se nó folha\n",
    "            return 0\n",
    "        total_gain = self.information_gain\n",
    "        for child in self.nodes.values():\n",
    "            total_gain += child.total_information_gain()\n",
    "        return total_gain\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um modelo de K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFold:\n",
    "    \"\"\"Classificador K-Fold de validação cruzada\"\"\"\n",
    "\n",
    "    def __init__(self, n_splits: int = 10, shuffle: bool = True, random_seed: int = None):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    def split(self, features: np.array, labels=np.array)-> Tuple[np.ndarray, np.ndarray]:\n",
    "        \n",
    "        \"\"\"\"Divide os dados em n partes para validação cruzada\n",
    "            > [INPUT]: Array de features e labels\\n\n",
    "            > [OUTPUT]: Tupla de arrays com os índices de treino e teste para cada fold\n",
    "        \"\"\"\n",
    "\n",
    "        n_samples = len(features)\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng = np.random.default_rng(self.random_seed)\n",
    "            indices = rng.permutation(indices)\n",
    "        \n",
    "        fold_sizes = np.full(self.n_splits, n_samples // self.n_splits, dtype=int)\n",
    "        fold_sizes[:n_samples % self.n_splits] += 1  # Distribui o resto\n",
    "\n",
    "\n",
    "        current = 0\n",
    "        for fold_size in fold_sizes:\n",
    "            start, stop = current, current + fold_size\n",
    "\n",
    "            #indices para teste e treino\n",
    "            test_idx = indices[start:stop]\n",
    "            train_idx = np.concatenate([indices[:start], indices[stop:]])\n",
    "\n",
    "            current = stop\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares para as saídas do algorítimo\n",
    "- ganho de informação\n",
    "- acurácia\n",
    "- sensibilidade\n",
    "- especificidade\n",
    "- precisão\n",
    "- f1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, positive_label):\n",
    "    tp = np.sum((y_true == positive_label) & (y_pred == positive_label))\n",
    "    tn = np.sum((y_true != positive_label) & (y_pred != positive_label))\n",
    "    fp = np.sum((y_true != positive_label) & (y_pred == positive_label))\n",
    "    fn = np.sum((y_true == positive_label) & (y_pred != positive_label))\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def precision(tp, fp):\n",
    "    return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "def f1_score(p, r):\n",
    "    return 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "def specificity(tn, fp):\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "def cross_validate(X, y, kfold, max_depth=4):\n",
    "\n",
    "    gains = []\n",
    "    accs = []\n",
    "    senss = []\n",
    "    specs = []\n",
    "    precs = []\n",
    "    f1s = []\n",
    "\n",
    "    positive_label = y.mode()[0]\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X.values, y.values):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        atributos = list(X.columns)\n",
    "        tree = decisionTreeNode(max_depth=max_depth)\n",
    "        tree.fit(X_train, y_train, atributos)\n",
    "\n",
    "        # Soma do ganho de informação total da árvore treinada neste fold\n",
    "        gains.append(tree.total_information_gain())\n",
    "\n",
    "        y_pred = []\n",
    "        for i in range(len(X_test)):\n",
    "            sample = X_test.iloc[i]\n",
    "            pred = tree.predict(sample)\n",
    "            y_pred.append(pred)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        acc = accuracy(y_test.values, y_pred)\n",
    "        tp, tn, fp, fn = confusion_matrix(y_test.values, y_pred, positive_label)\n",
    "\n",
    "        p = precision(tp, fp)\n",
    "        r = recall(tp, fn)\n",
    "        f1 = f1_score(p, r)\n",
    "        spec = specificity(tn, fp)\n",
    "\n",
    "        accs.append(acc)\n",
    "        senss.append(r)\n",
    "        specs.append(spec)\n",
    "        precs.append(p)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    print(f'Média Ganho de Informação: {np.mean(gains):.4f}')\n",
    "    print(f'Média Acurácia: {np.mean(accs):.4f}')\n",
    "    print(f'Média Sensibilidade: {np.mean(senss):.4f}')\n",
    "    print(f'Média Especificidade: {np.mean(specs):.4f}')\n",
    "    print(f'Média Precisão: {np.mean(precs):.4f}')\n",
    "    print(f'Média F1-Score: {np.mean(f1s):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando o treino com k-fold = 10 e árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média Ganho de Informação: 7.3756\n",
      "Média Acurácia: 0.9265\n",
      "Média Sensibilidade: 0.9369\n",
      "Média Especificidade: 0.9028\n",
      "Média Precisão: 0.9578\n",
      "Média F1-Score: 0.9470\n"
     ]
    }
   ],
   "source": [
    "# Separarando atributos e rótulos\n",
    "X = car_df.drop(columns=['Car_Acceptability'])\n",
    "y = car_df['Car_Acceptability']\n",
    "\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].astype('category').cat.codes\n",
    "y = y.astype('category')\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_seed=42)\n",
    "cross_validate(X, y, kfold, max_depth=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
